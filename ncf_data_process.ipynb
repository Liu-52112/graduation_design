{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "negative_label = []\n",
    "negative_users = []\n",
    "negative_items = []\n",
    "with open ('ncf_data/Data/ml-1m.test.negative', 'r') as file:\n",
    "    for line in file:\n",
    "        data = line.split('\\t')\n",
    "        x = data[0].split(',')\n",
    "        user = int(x[0][1:])\n",
    "        item1 = int(x[1][0:-1])\n",
    "        negative_users.append(user)\n",
    "        negative_items.append(item1)\n",
    "        negative_label.append(0)\n",
    "        for i in range(1,100):\n",
    "            negative_users.append(user)\n",
    "            negative_items.append(int(data[i]))\n",
    "            negative_label.append(0)\n",
    "len(negative_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = {}\n",
    "with open('ncf_data/Data/ml-1m.test.rating', 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip().split('\\t')\n",
    "        test_data[int(line[0])] = int(line[1])\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6039"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_users = []\n",
    "pos_items = []\n",
    "pos_label = []\n",
    "train_mat = []\n",
    "with open(\"ncf_data/Data/ml-1m.train.rating\", 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.rstrip().split('\\t')\n",
    "        pos_users.append(int(line[0]))\n",
    "        pos_items.append(int(line[1]))\n",
    "        pos_label.append(1)\n",
    "        train_mat.append((int(line[0]), int(line[1])))\n",
    "len(pos_users)\n",
    "num_users = max(pos_users)\n",
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3705"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = max(pos_items)\n",
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994169\n"
     ]
    }
   ],
   "source": [
    "num_users = max(pos_users)\n",
    "num_items = max(pos_items)\n",
    "print(len(pos_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4970845\n"
     ]
    }
   ],
   "source": [
    "from GMF import GMF\n",
    "from dataprocess import *\n",
    "from dataloader import *\n",
    "\n",
    "\n",
    "training_dataset = InteractionDataset(num_items,pos_users, pos_items, pos_label, ng_s=4, is_training=True)\n",
    "batch_size = 256\n",
    "print(len(training_dataset))\n",
    "shuffle = True\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size = batch_size, shuffle = shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NCF_ import NCF\n",
    "\n",
    "#model = GMF(num_users+1, num_items+1, 64)\n",
    "#model = NCF(user_num=num_users+1, item_num=num_items+1, factor_num=64, num_layers=1, dropout=0, model='GMF')\n",
    "model = NCF(user_num=num_users+1, item_num=num_items+1, factor_num=16, num_layers=3, dropout=0.0, model='NeuMF-end')\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epoch = 0\n",
    "best_epoch = 0\n",
    "best_hr = 0\n",
    "best_ndcg = 0\n",
    "no_improvement_epoch = 0\n",
    "max_no_improvement_epochs = 0\n",
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:: 100%|██████████| 994169/994169 [00:08<00:00, 123542.96it/s]\n",
      "Epoch 1: 100%|██████████| 19418/19418 [01:14<00:00, 261.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Loss = 0.3111 HR_10 = 0.6147350993 NDCG_10 = 0.3521036504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:: 100%|██████████| 994169/994169 [00:07<00:00, 125741.43it/s]\n",
      "Epoch 2: 100%|██████████| 19418/19418 [01:08<00:00, 283.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Loss = 0.2647 HR_10 = 0.6559602649 NDCG_10 = 0.3832654465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:: 100%|██████████| 994169/994169 [00:08<00:00, 123322.14it/s]\n",
      "Epoch 3: 100%|██████████| 19418/19418 [01:11<00:00, 270.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Loss = 0.2525 HR_10 = 0.6741721854 NDCG_10 = 0.3973294808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:: 100%|██████████| 994169/994169 [00:08<00:00, 121207.61it/s]\n",
      "Epoch 4: 100%|██████████| 19418/19418 [01:11<00:00, 270.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Loss = 0.2454 HR_10 = 0.6807947020 NDCG_10 = 0.4030029676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:: 100%|██████████| 994169/994169 [00:08<00:00, 122810.39it/s]\n",
      "Epoch 5: 100%|██████████| 19418/19418 [01:15<00:00, 257.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Loss = 0.2409 HR_10 = 0.6829470199 NDCG_10 = 0.4074795656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:: 100%|██████████| 994169/994169 [00:07<00:00, 124751.35it/s]\n",
      "Epoch 6: 100%|██████████| 19418/19418 [01:15<00:00, 256.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Loss = 0.2370 HR_10 = 0.6874172185 NDCG_10 = 0.4117573181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:: 100%|██████████| 994169/994169 [00:08<00:00, 123202.70it/s]\n",
      "Epoch 7:  75%|███████▍  | 14515/19418 [02:16<00:45, 106.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(user_ids, item_ids)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evaluate import *\n",
    "negative_users = torch.tensor(negative_users)\n",
    "negative_items = torch.tensor(negative_items)   \n",
    "while True:\n",
    "    total_loss=0\n",
    "    epoch = epoch +1\n",
    "    model.train()\n",
    "    training_loader.dataset.generate_ngs()\n",
    "    for user_ids, item_ids, labels in tqdm(training_loader, desc= \"Epoch \"+str(epoch)+\": \"):\n",
    "        labels = labels.float()\n",
    "        model.zero_grad()\n",
    "        outputs = model(user_ids, item_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    model.eval()\n",
    "    pred = predict_all_items(model,negative_users, negative_items)\n",
    "    topk = get_top_k_items_for_each_user(pred, 10)\n",
    "    hr = calculate_hit_rate(topk, test_data)\n",
    "    ndcg = calclulate_ndcg(topk, test_data)\n",
    "    avg_loss = total_loss / len(training_loader)\n",
    "    print(f\"Avg. Loss = {avg_loss:.4f} HR_10 = {hr:.10f} NDCG_10 = {ndcg:.10f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
